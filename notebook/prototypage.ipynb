{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b29a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin du fichier de conversation: ..\\data\\DISTRIBUTION_ACCUEIL_UBS\\TRANS_TXT\u00018_00000013.txt\n",
      "Démarrage du système RAG...\n",
      "✗ pgvector non disponible: ERREUR:  l'extension « vector » n'est pas disponible\n",
      "HINT:  Les extensions doivent tout d'abord être installées sur le système où PostgreSQL est exécuté.\n",
      "\n",
      "✓ Utilisation du fallback avec FLOAT8[]\n",
      "✓ Table embeddings créée\n",
      "Erreur lors de la lecture du fichier: [Errno 22] Invalid argument: '..\\\\data\\\\DISTRIBUTION_ACCUEIL_UBS\\\\TRANS_TXT\\x018_00000013.txt'\n",
      "Aucune donnée à traiter\n"
     ]
    }
   ],
   "source": [
    "# faire les importations nécessaires\n",
    "import psycopg2\n",
    "import google.generativeai as genai\n",
    "from psycopg2 import sql\n",
    "import numpy as np\n",
    "\n",
    "# Déclarer les variables nécessaires\n",
    "conversation_file_path = \"..\\data\\DISTRIBUTION_ACCUEIL_UBS\\TRANS_TXT\\018_00000013.txt\" \n",
    "print(f\"Chemin du fichier de conversation: {conversation_file_path}\")\n",
    "model = \"models/embedding-001\"  # Modèle d'embedding de Gemini\n",
    "\n",
    "# Initialiser le client Gemini\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "db_connection_str = \"dbname=rag_chatbot user=postgres password=tasnim host=localhost port=5432\"\n",
    "\n",
    "def create_conversation_list(file_path: str) -> list[str]:\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            text_list = text.split(\"\\n\")\n",
    "            filtered_list = [chaine.strip() for chaine in text_list if chaine.strip() and not chaine.startswith(\"<\")]\n",
    "            print(f\"Nombre de conversations chargées: {len(filtered_list)}\")\n",
    "            return filtered_list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fichier non trouvé: {file_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_embeddings(corpus: str) -> list[float]:\n",
    "    \"\"\"Calcule les embeddings avec Gemini\"\"\"\n",
    "    try:\n",
    "        result = genai.embed_content(\n",
    "            model=model,\n",
    "            content=corpus,\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "        return result['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du calcul de l'embedding: {e}\")\n",
    "        return []\n",
    "\n",
    "def setup_database(db_connection_str: str) -> bool:\n",
    "    \"\"\"Configure la base de données et retourne True si pgvector est disponible\"\"\"\n",
    "    try:\n",
    "        with psycopg2.connect(db_connection_str) as conn:\n",
    "            conn.autocommit = True\n",
    "            with conn.cursor() as cur:\n",
    "                # Essayer de créer l'extension pgvector\n",
    "                try:\n",
    "                    cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "                    print(\"✓ Extension pgvector activée\")\n",
    "                    return True\n",
    "                except Exception as e:\n",
    "                    print(f\"✗ pgvector non disponible: {e}\")\n",
    "                    print(\"✓ Utilisation du fallback avec FLOAT8[]\")\n",
    "                    return False\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de connexion à la base: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_table_with_fallback(db_connection_str: str, use_vector: bool):\n",
    "    \"\"\"Crée la table avec le type approprié\"\"\"\n",
    "    with psycopg2.connect(db_connection_str) as conn:\n",
    "        conn.autocommit = True\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"DROP TABLE IF EXISTS embeddings;\")\n",
    "            \n",
    "            if use_vector:\n",
    "                # Avec pgvector\n",
    "                create_table_query = \"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS embeddings (\n",
    "                    ID SERIAL PRIMARY KEY, \n",
    "                    corpus TEXT,\n",
    "                    embedding VECTOR(768)\n",
    "                );\n",
    "                \"\"\"\n",
    "            else:\n",
    "                # Fallback sans pgvector\n",
    "                create_table_query = \"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS embeddings (\n",
    "                    ID SERIAL PRIMARY KEY, \n",
    "                    corpus TEXT,\n",
    "                    embedding FLOAT8[]\n",
    "                );\n",
    "                \"\"\"\n",
    "            \n",
    "            cur.execute(create_table_query)\n",
    "            print(\"✓ Table embeddings créée\")\n",
    "\n",
    "def save_embedding(corpus: str, embedding: list[float], cursor, use_vector: bool) -> None:\n",
    "    \"\"\"Sauvegarde l'embedding dans la base de données\"\"\"\n",
    "    try:\n",
    "        if use_vector:\n",
    "            # Pour pgvector\n",
    "            embedding_array = \"[\" + \",\".join(str(x) for x in embedding) + \"]\"\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO embeddings (corpus, embedding) VALUES (%s, %s)''', \n",
    "                (corpus, embedding_array)\n",
    "            )\n",
    "        else:\n",
    "            # Pour FLOAT8[]\n",
    "            embedding_array = \"{\" + \",\".join(str(x) for x in embedding) + \"}\"\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO embeddings (corpus, embedding) VALUES (%s, %s)''', \n",
    "                (corpus, embedding_array)\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde: {e}\")\n",
    "\n",
    "def similar_corpus(input_corpus: str, db_connection_str: str, use_vector: bool, top_k: int = 5) -> list[tuple]:\n",
    "    \"\"\"\n",
    "    Trouve les textes similaires dans la base de données\n",
    "    \"\"\"\n",
    "    input_embedding = calculate_embeddings(input_corpus)\n",
    "    if not input_embedding:\n",
    "        print(\"Erreur: Impossible de calculer l'embedding de la requête\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        with psycopg2.connect(db_connection_str) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                if use_vector:\n",
    "                    # Requête avec pgvector\n",
    "                    input_embedding_array = \"[\" + \",\".join(str(x) for x in input_embedding) + \"]\"\n",
    "                    query = \"\"\"\n",
    "                    SELECT id, corpus, \n",
    "                           embedding <=> %s::vector AS distance\n",
    "                    FROM embeddings \n",
    "                    ORDER BY embedding <=> %s::vector\n",
    "                    LIMIT %s\n",
    "                    \"\"\"\n",
    "                else:\n",
    "                    # Requête sans pgvector (similarité cosinus manuelle)\n",
    "                    input_embedding_array = \"{\" + \",\".join(str(x) for x in input_embedding) + \"}\"\n",
    "                    query = \"\"\"\n",
    "                    SELECT id, corpus,\n",
    "                           sqrt(power(embedding - %s, 2)) as distance\n",
    "                    FROM embeddings \n",
    "                    ORDER BY distance\n",
    "                    LIMIT %s\n",
    "                    \"\"\"\n",
    "                \n",
    "                if use_vector:\n",
    "                    cur.execute(query, (input_embedding_array, input_embedding_array, top_k))\n",
    "                else:\n",
    "                    cur.execute(query, (input_embedding_array, top_k))\n",
    "                \n",
    "                results = cur.fetchall()\n",
    "                \n",
    "                print(f\"Top {len(results)} résultats similaires:\")\n",
    "                for i, (id, corpus, distance) in enumerate(results, 1):\n",
    "                    print(f\"{i}. ID: {id}, Distance: {distance:.4f}\")\n",
    "                    print(f\"   Texte: {corpus[:100]}...\")\n",
    "                    print(\"-\" * 80)\n",
    "                \n",
    "                return results\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la recherche: {e}\")\n",
    "        return []\n",
    "\n",
    "# Exécution principale\n",
    "print(\"Démarrage du système RAG...\")\n",
    "\n",
    "# Étape 1: Configuration de la base\n",
    "use_vector = setup_database(db_connection_str)\n",
    "\n",
    "# Étape 2: Création de la table\n",
    "create_table_with_fallback(db_connection_str, use_vector)\n",
    "\n",
    "# Étape 3: Chargement et traitement des données\n",
    "corpus_list = create_conversation_list(file_path=conversation_file_path)\n",
    "\n",
    "if corpus_list:\n",
    "    with psycopg2.connect(db_connection_str) as conn:\n",
    "        conn.autocommit = True\n",
    "        with conn.cursor() as cur:\n",
    "            for i, corpus in enumerate(corpus_list):\n",
    "                if corpus.strip() and len(corpus) > 10:  # Ignorer les textes trop courts\n",
    "                    print(f\"Traitement du corpus {i+1}/{len(corpus_list)}: {corpus[:50]}...\")\n",
    "                    embedding = calculate_embeddings(corpus=corpus)\n",
    "                    if embedding:\n",
    "                        save_embedding(corpus=corpus, embedding=embedding, cursor=cur, use_vector=use_vector)\n",
    "            \n",
    "            conn.commit()\n",
    "            print(\"✓ Tous les embeddings ont été sauvegardés\")\n",
    "\n",
    "    # Étape 4: Test de recherche\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TEST DE RECHERCHE PAR SIMILARITÉ\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    test_queries = [\n",
    "        \"Bonjour, comment puis-je vous aider ?\",\n",
    "        \"Je cherche des informations\",\n",
    "        \"Problème avec mon compte\"\n",
    "    ]\n",
    "\n",
    "    for test_query in test_queries:\n",
    "        print(f\"\\nRecherche pour: '{test_query}'\")\n",
    "        similar_results = similar_corpus(\n",
    "            input_corpus=test_query, \n",
    "            db_connection_str=db_connection_str,\n",
    "            use_vector=use_vector,\n",
    "            top_k=3\n",
    "        )\n",
    "else:\n",
    "    print(\"Aucune donnée à traiter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
